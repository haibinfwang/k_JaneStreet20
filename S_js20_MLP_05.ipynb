{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jane Street 2020: Multi-Layer Perceptron V\n",
    "\n",
    "Using MLP to classify\n",
    " - Using EMA on features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Summary, and initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.7.1; cuda available: True\n",
      "     active environment : base\n",
      "working directory: /home/AWC/wang/learn/kaggle/k_JaneStreet20\n"
     ]
    }
   ],
   "source": [
    "# Imports, environment, and paths\n",
    "import os, sys, gc, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datatable as dtable\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, log_loss\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background') #plt.style.use('default')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import janestreet\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "print(f'PyTorch version: {torch.__version__}; cuda available: {torch.cuda.is_available()}')\n",
    "\n",
    "# auxiliary --------------\n",
    "from importlib import reload\n",
    "import time\n",
    "\n",
    "# Print environment ------\n",
    "pd.set_option('display.max_columns', 200) \n",
    "!conda info | grep 'active environment' # or use: !conda info --envs | grep '*'\n",
    "print(f'working directory: {os.getcwd()}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducability\n",
    "# globalSeed=67\n",
    "# np.random.seed(globalSeed) # for reproducibility, does this work?\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing warning before saving the presentation, only\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "\n",
    "Variables for later sections:\n",
    " - data, features: \n",
    " - nFeat, daySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.8 s, sys: 4.18 s, total: 59.9 s\n",
      "Wall time: 5.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ddir='~/learn/kaggle/Data/JaneStreet20' # local\n",
    "# ddir='../input/jane-street-market-prediction' # kaggle\n",
    "\n",
    "# data = pd.read_csv(os.path.join(ddir,\"train.csv\"))\n",
    "data = dtable.fread(os.path.join(ddir,\"train.csv\")).to_pandas() # using datatable for faster loading\n",
    "features = pd.read_csv(os.path.join(ddir,\"features.csv\"))\n",
    "\n",
    "nFeat=features.shape[0]\n",
    "featName=[f'feature_{n}' for n in range(nFeat)]\n",
    "xywCol=featName+['resp','weight']\n",
    "daySet=data['date'].unique()\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Preprecessing\n",
    "\n",
    "The data may be used in later sections are\n",
    " - dataBlock\n",
    " - data_t, data_v, data_c for TVT data\n",
    " - nFeat, featName\n",
    " - norm, for normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Deal with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def fillNanWithinDay(df,dayCol,fillCol,spanFillNa=1):\n",
    "    \"\"\"fill NaN within date\n",
    "    \n",
    "    This function does (forward) fill without crossing dates, using EMA of a trailing\n",
    "    window. Equal value in dayCol column indicates same date. \"Date\" here can\n",
    "    be generalized to block with equal dayCol value\n",
    "    Parameter:\n",
    "      df: dataframe, original data\n",
    "      dayCol: string, column name. Equal value indicates same date (block)\n",
    "      fillCol: list of straings, names of columns to fill NaN\n",
    "      spanFillNa: integer. Using a trailing ema of given span to fill NaN.\n",
    "          spanFillNa=1 is equivalent to 'ffill' of df.fillna()\n",
    "    return:\n",
    "      list of pd.DataFrame of day, NaN replaced\n",
    "    \"\"\"\n",
    "    dfList=[]\n",
    "    dayList=df[dayCol].unique()\n",
    "    for day in dayList:\n",
    "        data_1=df.loc[df['date']==day]\n",
    "        data_1_=data_1[fillCol].ewm(span=spanFillNa,adjust=False,ignore_na=True).mean()\n",
    "        data_1_fill=data_1.copy()\n",
    "        for cname in fillCol:\n",
    "            toFill=data_1[cname].isna()\n",
    "            data_1_fill.loc[toFill,cname]=data_1_.loc[toFill,cname]\n",
    "        dfList.append(data_1_fill)\n",
    "    \n",
    "    return pd.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#original:  2390491\n",
      "CPU times: user 1min 15s, sys: 4.42 s, total: 1min 19s\n",
      "Wall time: 1min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fill NaN after first data points of day\n",
    "spanFillNa=3\n",
    "fillCol=[f'feature_{ii}' for ii in range(nFeat) if ii not in [0,64]] # features to fill nan\n",
    "data=fillNanWithinDay(data,'date',fillCol,spanFillNa=spanFillNa)\n",
    "print('#original: ',data.shape[0])\n",
    "\n",
    "# Fill NaN on beginning of day\n",
    "nPointStart=300 # num of samples to estimate day start\n",
    "dayStart=[data.loc[data['date']==day,fillCol].iloc[:nPointStart] for day in daySet]\n",
    "f_mean=pd.concat(dayStart).mean()\n",
    "data[fillCol] = data[fillCol].fillna(f_mean)\n",
    "f_mean.to_csv(os.path.join('fmean_JS20_MLP_01.csv')) # './model_sv'\n",
    "\n",
    "data=data.loc[~data[xywCol].isna().any(axis=1)]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#After dropping NaN and 0 wieghts:  1981287\n",
      "#Nan in train: 0, 0, 0\n"
     ]
    }
   ],
   "source": [
    "# EMA of features\n",
    "spanFeat=8\n",
    "emaFeatName=[f'feature_{kk}' for kk in [54,50,61,62,63,66,67,68,122,123,125,125,126,127,128]]\n",
    "emaCol={cn:cn+'_ema' for cn in emaFeatName}\n",
    "# emaFeatName=[val for _,val in emaCol.items()]\n",
    "\n",
    "dayList=data['date'].unique()\n",
    "data_ema=[data.loc[data['date']==day,emaFeatName].ewm(span=spanFeat,adjust=False,ignore_na=True).mean() for day in\n",
    "         dayList]\n",
    "data_ema=pd.concat(data_ema).rename(columns=emaCol)\n",
    "data=pd.concat([data,data_ema],axis=1)\n",
    "\n",
    "# Drop 0 weight\n",
    "data=data.loc[data['weight']>0].reset_index(drop=True)  # Dropping 0 weight\n",
    "print('#After dropping NaN and 0 wieghts: ',data.shape[0])\n",
    "\n",
    "print('#Nan in train: {:d}, {:d}, {:d}'.format(data.loc[:,featName].isna().to_numpy().sum(),\n",
    "                                               data.loc[:,'resp'].isna().to_numpy().sum(),\n",
    "                                               data.loc[:,'weight'].isna().to_numpy().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2390491, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ema.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Traing MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,nFeat):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm0 = torch.nn.BatchNorm1d(nFeat)\n",
    "        self.dropout0 = torch.nn.Dropout(0.10143786981358652)\n",
    "\n",
    "        self.dense1 = torch.nn.Linear(nFeat, 3001)\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(3001)\n",
    "        self.dropout1 = torch.nn.Dropout(0.19720339053599725)\n",
    "\n",
    "        self.dense2 = torch.nn.Linear(3001, 1324)\n",
    "        self.batch_norm2 = torch.nn.BatchNorm1d(1324)\n",
    "        self.dropout2 = torch.nn.Dropout(0.2703017847244654)\n",
    "\n",
    "        self.dense3 = torch.nn.Linear(1324, 718)\n",
    "        self.batch_norm3 = torch.nn.BatchNorm1d(718)\n",
    "        self.dropout3 = torch.nn.Dropout(0.23148340929571917)\n",
    "        \n",
    "        self.dense4 = torch.nn.Linear(718, 110)\n",
    "        self.batch_norm4 = torch.nn.BatchNorm1d(110)\n",
    "        self.dropout4 = torch.nn.Dropout(0.2357768967777311)\n",
    "        \n",
    "        self.dense5 = torch.nn.Linear(110, 512)\n",
    "        self.batch_norm5 = torch.nn.BatchNorm1d(512)\n",
    "        self.dropout5 = torch.nn.Dropout(0.2357768967777311)\n",
    "\n",
    "        self.dense6 = torch.nn.Linear(512, 394)\n",
    "        self.batch_norm6 = torch.nn.BatchNorm1d(394)\n",
    "        self.dropout6 = torch.nn.Dropout(0.2357768967777311)\n",
    "        \n",
    "        self.dense7 = torch.nn.Linear(394, 128)\n",
    "        self.batch_norm7 = torch.nn.BatchNorm1d(128)\n",
    "        self.dropout7 = torch.nn.Dropout(0.2357768967777311)\n",
    "\n",
    "        self.dense_out = torch.nn.Linear(64, 1)\n",
    "\n",
    "        self.Relu = torch.nn.ReLU(inplace=True)\n",
    "        self.PReLU = torch.nn.PReLU()\n",
    "        self.LeakyReLU = torch.nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        # self.GeLU = torch.nn.GELU()\n",
    "        self.RReLU = torch.nn.RReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm0(x)\n",
    "        x = self.dropout0(x)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        #x = x * torch.sigmoid(x)\n",
    "        x=self.Relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        #x = x * torch.sigmoid(x)\n",
    "        x=self.Relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x=self.Relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.dense4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        #x = x * torch.sigmoid(x)\n",
    "        x=self.Relu(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = self.dense5(x)\n",
    "        x = self.batch_norm5(x)\n",
    "        x=self.Relu(x)\n",
    "        x = self.dropout5(x)\n",
    "        \n",
    "        x = self.dense6(x)\n",
    "        x = self.batch_norm6(x)\n",
    "        x=self.Relu(x)\n",
    "        x = self.dropout6(x)\n",
    "        \n",
    "        x = self.dense7(x)\n",
    "        x = self.batch_norm7(x)\n",
    "        x=self.Relu(x)\n",
    "        x = self.dropout7(x)\n",
    "\n",
    "        x = self.dense_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Trainging: helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDataset:\n",
    "    def __init__(self, data, featName):\n",
    "        self.features = data[featName].values\n",
    "        self.label = (data['resp']>0).astype('int').values.reshape(-1, 1)\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.features[idx], dtype=torch.float),\n",
    "            'label': torch.tensor(self.label[idx], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        features = data['features'].to(device)\n",
    "        label = data['label'].to(device)\n",
    "        outputs = model(features)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        final_loss += loss.item()\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        features = data['features'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(features)\n",
    "\n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds).reshape(-1)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score: #  + self.delta\n",
    "            self.counter += 1\n",
    "            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            # ema.apply_shadow()\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            # ema.restore()\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_score_bincount(date, weight, resp, action):\n",
    "    count_i = len(np.unique(date))\n",
    "    # print('weight: ', weight)\n",
    "    # print('resp: ', resp)\n",
    "    # print('action: ', action)\n",
    "    # print('weight * resp * action: ', weight * resp * action)\n",
    "    Pi = np.bincount(date, weight * resp * action)\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
    "    u = np.clip(t, 0, 6) * np.sum(Pi)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f9110ca9a0f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mvalid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'resp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c451466c33b4>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, optimizer, scheduler, loss_fn, dataloader, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-627e0431c336>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "batch_size = 4096\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ckp_path = os.path.join('JS20_MLP_01.pth') # './model_sv'\n",
    "\n",
    "# gkf = GroupKFold(n_splits = 5)\n",
    "gss = GroupShuffleSplit(n_splits=5, test_size=0.2)\n",
    "for fold, (idx_t, idx_v) in enumerate(gss.split(data, groups=data['date'])):\n",
    "    # print(f'fold {fold}: ',len(idx_t),len(idx_v),len(idx_t)+len(idx_v))\n",
    "    \n",
    "    train_set = MarketDataset(data.loc[idx_t],featName+emaFeatName)\n",
    "    train_loader=DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_set = MarketDataset(data.loc[idx_v],featName+emaFeatName)\n",
    "    valid_loader=DataLoader(valid_set, batch_size=batch_size, shuffle=False) # Using True is bad, why??????????\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    model = Model(len(featName+emaFeatName))\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = SmoothBCEwLogits(smoothing=label_smoothing)\n",
    "    es = EarlyStopping(patience=3, mode=\"max\")\n",
    "\n",
    "    ckp_path = f'JS20_MLP_05_{fold}.pth'\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        train_loss = train_fn(model, optimizer, None, loss_fn, train_loader, device)\n",
    "        valid_pred = inference_fn(model, valid_loader, device)\n",
    "        auc_score = roc_auc_score((data.loc[idx_v,'resp']>0).astype(int).values.reshape(-1, 1), valid_pred)\n",
    "        logloss_score = log_loss((data.loc[idx_v,'resp']>0).astype(int).values.reshape(-1, 1), valid_pred)\n",
    "        valid_pred = np.where(valid_pred >= 0.5, 1, 0).astype(int)\n",
    "\n",
    "        u_score = utility_score_bincount(date=data.loc[idx_v,'date'].values, weight=data.loc[idx_v,'weight'].values,\n",
    "                                         resp=data.loc[idx_v,'resp'].values, action=valid_pred)\n",
    "        print(f\"EPOCH:{epoch:3}, train_loss:{train_loss:.5f}, u_score:{u_score:.5f}, auc:{auc_score:.5f}, logloss:{logloss_score:.5f}, \"\n",
    "              f\"time: {(time.time() - start_time) / 60:.2f}min\")\n",
    "\n",
    "        es(auc_score, model, model_path=ckp_path)\n",
    "        if es.early_stop:\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "    break # only train 1 model for fast, you can remove it to train 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCH:  0, train_loss:0.69311, u_score:1252.46847, auc:0.53161, logloss:0.69114, time: 1.13min\n",
    "# Validation score improved (-inf --> 0.531611473976248). Saving model!\n",
    "# EPOCH:  1, train_loss:0.69083, u_score:1494.60356, auc:0.52942, logloss:0.69150, time: 2.26min\n",
    "# EarlyStopping counter: 1 out of 3\n",
    "# EPOCH:  2, train_loss:0.69008, u_score:1475.69509, auc:0.53158, logloss:0.69124, time: 3.40min\n",
    "# EarlyStopping counter: 2 out of 3\n",
    "# EPOCH:  3, train_loss:0.68919, u_score:2119.23536, auc:0.53358, logloss:0.69088, time: 4.49min\n",
    "# Validation score improved (0.531611473976248 --> 0.5335764266654076). Saving model!\n",
    "# EPOCH:  4, train_loss:0.68825, u_score:1170.78415, auc:0.53083, logloss:0.69242, time: 5.56min\n",
    "# EarlyStopping counter: 1 out of 3\n",
    "# EPOCH:  5, train_loss:0.68696, u_score:1035.60073, auc:0.52705, logloss:0.69337, time: 6.67min\n",
    "# EarlyStopping counter: 2 out of 3\n",
    "# EPOCH:  6, train_loss:0.68568, u_score:1591.23117, auc:0.53299, logloss:0.69391, time: 7.80min\n",
    "# EarlyStopping counter: 3 out of 3\n",
    "# Early stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "ckp_path_list=[]\n",
    "for i in range(5): # for fast inference, you can change 1-->5 to get higher score\n",
    "    torch.cuda.empty_cache()\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = Model(len(featName+emaFeatName))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    ckp_path = f'JS20_MLP_05_{i}.pth'\n",
    "    ckp_path_list.append(ckp_path)\n",
    "    model.load_state_dict(torch.load(ckp_path))\n",
    "    models.append(model)\n",
    "print(f'Loaded')\n",
    "print(ckp_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try not to use GPU here ******\n",
    "\n",
    "# env = janestreet.make_env()\n",
    "# env_iter = env.iter_test()\n",
    "\n",
    "# alpha=2/(spanFillNa+1)\n",
    "# prevDate=None\n",
    "# opt_th=0.5\n",
    "# nTest=0\n",
    "# for (test_df_1, pred_df) in tqdm(env_iter):\n",
    "#     test_df=test_df_1.iloc[0]\n",
    "#     # Update fill value\n",
    "#     if prevDate!=test_df['date']:\n",
    "#         xx_fill=test_df[fillCol].fillna(f_mean)\n",
    "#     else:\n",
    "#         xx_fill=(((1-alpha)*xx_fill+alpha*test_df[fillCol].fillna(0))*(~test_df[fillCol].isna()) +\n",
    "#                  xx_fill*test_df[fillCol].isna() )\n",
    "#     if xx_fill.isna().any():\n",
    "#         print('xx_fill contains NaN'); break\n",
    "    \n",
    "#     if test_df['weight'].item() > 0:\n",
    "#         xx=test_df.loc[featName].copy()\n",
    "#         if xx[fillCol].isna().any():\n",
    "#             xx[fillCol]=test_df[fillCol].fillna(xx_fill)\n",
    "#         for i, clf in enumerate(models):\n",
    "#             if i == 0:\n",
    "#                 pred=clf(torch.tensor(np.expand_dims(xx.values,axis=0),dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy()\n",
    "#             else:\n",
    "#                 pred+=clf(torch.tensor(np.expand_dims(xx.values,axis=0),dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy()\n",
    "#         pred/=len(models)\n",
    "#         pred_df.action=np.where(pred >= opt_th, 1, 0).astype(int)\n",
    "#     else:\n",
    "#         pred_df.action = 0\n",
    "#     env.predict(pred_df)\n",
    "#     prevDate=test_df['date']\n",
    "#     nTest+=1\n",
    "# print(f'nn={nTest}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_c=pd.read_csv(os.path.join(ddir,'example_test.csv') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Try not to use GPU here ******\n",
    "\n",
    "# # env = janestreet.make_env()\n",
    "# # env_iter = env.iter_test()\n",
    "\n",
    "# alpha_na=2/(spanFillNa+1)\n",
    "# alpha_feat=2/(spanFeat+1)\n",
    "# prevDate=None\n",
    "# opt_th=0.5\n",
    "# nTest=0\n",
    "# # for (test_df_1, pred_df) in tqdm(env_iter):\n",
    "# #     test_df=test_df_1.iloc[0]\n",
    "# for idx_c,test_df in data_c.iterrows():\n",
    "#     # Update fill value\n",
    "#     if prevDate!=test_df['date']:\n",
    "#         xx_fill=test_df[fillCol].fillna(f_mean)\n",
    "#     else:\n",
    "#         xx_fill=(((1-alpha_na)*xx_fill+alpha_na*test_df[fillCol].fillna(0))*(~test_df[fillCol].isna()) +\n",
    "#                  xx_fill*test_df[fillCol].isna() )\n",
    "#     if xx_fill.isna().any():\n",
    "#         print('xx_fill contains NaN'); break\n",
    "    \n",
    "#     xx=test_df.loc[featName].copy()\n",
    "#     if xx[fillCol].isna().any():\n",
    "#         xx[fillCol]=test_df[fillCol].fillna(xx_fill)\n",
    "    \n",
    "#     # EMA of features\n",
    "#     if prevDate!=test_df['date']:\n",
    "#         xx_ema=xx[emaFeatName]\n",
    "#     else:\n",
    "#         xx_ema=(1-alpha_feat)*xx_ema+alpha_feat*xx[emaFeatName]\n",
    "#     xx=pd.concat([xx,xx_ema.rename(index=emaCol)])\n",
    "\n",
    "#     if test_df['weight'].item() > 0:\n",
    "#         for i, clf in enumerate(models):\n",
    "#             if i == 0:\n",
    "#                 pred=clf(torch.tensor(np.expand_dims(xx.values,axis=0),dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy()\n",
    "#             else:\n",
    "#                 pred+=clf(torch.tensor(np.expand_dims(xx.values,axis=0),dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy()\n",
    "#         pred/=len(models)\n",
    "#         #pred_df.action=np.where(pred >= opt_th, 1, 0).astype(int)\n",
    "#     else:\n",
    "#         #pred_df.action = 0\n",
    "#         None\n",
    "#     # env.predict(pred_df)\n",
    "#     prevDate=test_df['date']\n",
    "#     nTest+=1\n",
    "#     if nTest>10:\n",
    "#         break\n",
    "# print(f'nn={nTest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
